{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:24:13.473930Z",
     "start_time": "2025-06-29T21:24:13.470368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Utilities\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import getpass\n",
    "import requests\n",
    "\n",
    "from sentinelhub import (\n",
    "    SHConfig,\n",
    "    DataCollection,\n",
    "    SentinelHubCatalog,\n",
    "    SentinelHubRequest,\n",
    "    SentinelHubStatistical,\n",
    "    BBox,\n",
    "    bbox_to_dimensions,\n",
    "    CRS,\n",
    "    MimeType,\n",
    "    Geometry,\n",
    ")\n",
    "\n",
    "from utils import plot_image"
   ],
   "id": "90cd0033ac543d12",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:25:13.895782Z",
     "start_time": "2025-06-29T21:25:13.889752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = SHConfig()\n",
    "config"
   ],
   "id": "abb952deb2a32439",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SHConfig(\n",
       "  instance_id='',\n",
       "  sh_client_id='***********************************a932',\n",
       "  sh_client_secret='****************************nN8E',\n",
       "  sh_base_url='https://sh.dataspace.copernicus.eu',\n",
       "  sh_auth_base_url=None,\n",
       "  sh_token_url='https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token',\n",
       "  geopedia_wms_url='https://service.geopedia.world',\n",
       "  geopedia_rest_url='https://www.geopedia.world/rest',\n",
       "  aws_access_key_id='',\n",
       "  aws_secret_access_key='',\n",
       "  aws_session_token='',\n",
       "  aws_metadata_url='https://roda.sentinel-hub.com',\n",
       "  aws_s3_l1c_bucket='sentinel-s2-l1c',\n",
       "  aws_s3_l2a_bucket='sentinel-s2-l2a',\n",
       "  opensearch_url='http://opensearch.sentinel-hub.com/resto/api/collections/Sentinel2',\n",
       "  max_wfs_records_per_query=100,\n",
       "  max_opensearch_records_per_query=500,\n",
       "  max_download_attempts=4,\n",
       "  download_sleep_time=5.0,\n",
       "  download_timeout_seconds=120.0,\n",
       "  number_of_download_processes=1,\n",
       "  max_retries=None,\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:24:34.640250Z",
     "start_time": "2025-06-29T21:24:34.637207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- AOI and time interval setup ---\n",
    "time_interval = ('2024-06-01', '2024-12-31')\n",
    "aoi_coords_wgs84 = [-117.272555, 32.392761, -117.083041, 32.678348]"
   ],
   "id": "27f3b56bd3e3f310",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:24:43.721621Z",
     "start_time": "2025-06-29T21:24:43.700292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- resolution setup ---\n",
    "resolution = 10\n",
    "aoi_bbox = BBox(bbox=aoi_coords_wgs84, crs=CRS.WGS84)\n",
    "aoi_size = bbox_to_dimensions(aoi_bbox, resolution=resolution)\n",
    "print(f\"Image shape at {resolution} m resolution: {aoi_size} pixels\")"
   ],
   "id": "5e2e2c50aa5e645e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape at 10 m resolution: (1785, 3163) pixels\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:25:41.231014Z",
     "start_time": "2025-06-29T21:25:23.147647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Catalog search ---\n",
    "catalog = SentinelHubCatalog(config=config)\n",
    "\n",
    "s1_iterator = catalog.search(\n",
    "    DataCollection.SENTINEL1_IW,\n",
    "    bbox=aoi_bbox,\n",
    "    time=time_interval,\n",
    "    fields={\"include\": [\"id\", \"properties.datetime\"], \"exclude\": []},\n",
    ")\n",
    "s1_results = list(s1_iterator)\n",
    "print(\"Sentinel-1 results:\", len(s1_results))\n",
    "\n",
    "s2_iterator = catalog.search(\n",
    "    DataCollection.SENTINEL2_L1C,\n",
    "    bbox=aoi_bbox,\n",
    "    time=time_interval,\n",
    "    fields={\"include\": [\"id\", \"properties.datetime\"], \"exclude\": []},\n",
    ")\n",
    "s2_results = list(s2_iterator)\n",
    "print(\"Sentinel-2 results:\", len(s2_results))\n",
    "\n",
    "# --- Convert results to DataFrames ---\n",
    "df_s1 = pd.DataFrame([{\n",
    "    \"id\": item[\"id\"],\n",
    "    \"datetime\": pd.to_datetime(item[\"properties\"][\"datetime\"]),\n",
    "    \"date\": pd.to_datetime(item[\"properties\"][\"datetime\"]).date()\n",
    "} for item in s1_results])\n",
    "\n",
    "df_s2 = pd.DataFrame([{\n",
    "    \"id\": item[\"id\"],\n",
    "    \"datetime\": pd.to_datetime(item[\"properties\"][\"datetime\"]),\n",
    "    \"date\": pd.to_datetime(item[\"properties\"][\"datetime\"]).date()\n",
    "} for item in s2_results])"
   ],
   "id": "c5929343d938f61d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentinel-1 results: 57\n",
      "Sentinel-2 results: 165\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:26:15.233564Z",
     "start_time": "2025-06-29T21:26:15.222694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Find overlapping dates ---\n",
    "common_dates = set(df_s1[\"date\"]).intersection(set(df_s2[\"date\"]))\n",
    "print(\"Number of matching dates:\", len(common_dates))\n",
    "\n",
    "# --- Filter and group by date ---\n",
    "df_s1_common = df_s1[df_s1[\"date\"].isin(common_dates)].copy()\n",
    "df_s2_common = df_s2[df_s2[\"date\"].isin(common_dates)].copy()\n",
    "\n",
    "grouped_s1 = df_s1_common.groupby(\"date\")[\"id\"].apply(list).rename(\"s1_ids\")\n",
    "grouped_s2 = df_s2_common.groupby(\"date\")[\"id\"].apply(list).rename(\"s2_ids\")\n",
    "\n",
    "matched_df = pd.concat([grouped_s1, grouped_s2], axis=1).reset_index()\n",
    "print(matched_df.head())"
   ],
   "id": "2c94cc6814228bea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matching dates: 13\n",
      "         date                                             s1_ids  \\\n",
      "0  2024-06-26  [S1A_IW_GRDH_1SDV_20240626T134456_20240626T134...   \n",
      "1  2024-07-01  [S1A_IW_GRDH_1SDV_20240701T135318_20240701T135...   \n",
      "2  2024-07-13  [S1A_IW_GRDH_1SDV_20240713T135318_20240713T135...   \n",
      "3  2024-08-25  [S1A_IW_GRDH_1SDV_20240825T134455_20240825T134...   \n",
      "4  2024-08-30  [S1A_IW_GRDH_1SDV_20240830T135318_20240830T135...   \n",
      "\n",
      "                                              s2_ids  \n",
      "0  [S2A_MSIL1C_20240626T182921_N0510_R027_T11SMR_...  \n",
      "1  [S2B_MSIL1C_20240701T182919_N0510_R027_T11SMR_...  \n",
      "2  [S2A_MSIL1C_20240713T181921_N0510_R127_T11SMR_...  \n",
      "3  [S2A_MSIL1C_20240825T182921_N0511_R027_T11SMR_...  \n",
      "4  [S2B_MSIL1C_20240830T182919_N0511_R027_T11SMR_...  \n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:30:49.484394Z",
     "start_time": "2025-06-29T21:30:49.473526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"matched_df columns:\", matched_df.columns.tolist())\n",
    "print(\"matched_df shape:\", matched_df.shape)\n",
    "print(\"\\nSample rows:\")\n",
    "print(matched_df.head(3))\n",
    "\n",
    "# Optional: look at one row's content clearly\n",
    "print(\"\\nExample row content:\")\n",
    "example_row = matched_df.iloc[0]\n",
    "print(\"Date:\", example_row[\"date\"])\n",
    "print(\"S1 IDs:\", example_row[\"s1_ids\"])\n",
    "print(\"S2 IDs:\", example_row[\"s2_ids\"])\n",
    "\n",
    "matched_df.to_csv(\"matched_s1_s2_ids.csv\", index=False)"
   ],
   "id": "4b0544cf9970ba33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched_df columns: ['date', 's1_ids', 's2_ids']\n",
      "matched_df shape: (13, 3)\n",
      "\n",
      "Sample rows:\n",
      "         date                                             s1_ids  \\\n",
      "0  2024-06-26  [S1A_IW_GRDH_1SDV_20240626T134456_20240626T134...   \n",
      "1  2024-07-01  [S1A_IW_GRDH_1SDV_20240701T135318_20240701T135...   \n",
      "2  2024-07-13  [S1A_IW_GRDH_1SDV_20240713T135318_20240713T135...   \n",
      "\n",
      "                                              s2_ids  \n",
      "0  [S2A_MSIL1C_20240626T182921_N0510_R027_T11SMR_...  \n",
      "1  [S2B_MSIL1C_20240701T182919_N0510_R027_T11SMR_...  \n",
      "2  [S2A_MSIL1C_20240713T181921_N0510_R127_T11SMR_...  \n",
      "\n",
      "Example row content:\n",
      "Date: 2024-06-26\n",
      "S1 IDs: ['S1A_IW_GRDH_1SDV_20240626T134456_20240626T134521_054495_06A1B9_E2D5_COG.SAFE']\n",
      "S2 IDs: ['S2A_MSIL1C_20240626T182921_N0510_R027_T11SMR_20240626T231652.SAFE', 'S2A_MSIL1C_20240626T182921_N0510_R027_T11SMS_20240626T231652.SAFE']\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                     Id  \\\n",
       "0  2a92387c-d802-4ac7-9b24-187e0e6d8ab4   \n",
       "1  1d42f2d3-2456-485f-a93e-92f08bdd5c51   \n",
       "2  5c744d5c-c082-4a34-a181-81cde73cd25d   \n",
       "\n",
       "                                                Name  \\\n",
       "0   c_gls_LIE250_202205030000_Baltic_MODIS_V1.2.2_nc   \n",
       "1  S1A_OPER_AUX_GNSSRD_POD__20220510T020122_V2022...   \n",
       "2  S1B_OPER_AUX_GNSSRD_POD__20220510T023113_V2022...   \n",
       "\n",
       "                                              S3Path  \\\n",
       "0  /eodata/CLMS/bio-geophysical/river_and_lake_ic...   \n",
       "1  /eodata/Sentinel-1/AUX/AUX_GNSSRD/2022/05/03/S...   \n",
       "2  /eodata/Sentinel-1/AUX/AUX_GNSSRD/2022/05/03/S...   \n",
       "\n",
       "                                        GeoFootprint  \n",
       "0  {'type': 'Polygon', 'coordinates': [[[4.99625,...  \n",
       "1                                               None  \n",
       "2                                               None  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>S3Path</th>\n",
       "      <th>GeoFootprint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2a92387c-d802-4ac7-9b24-187e0e6d8ab4</td>\n",
       "      <td>c_gls_LIE250_202205030000_Baltic_MODIS_V1.2.2_nc</td>\n",
       "      <td>/eodata/CLMS/bio-geophysical/river_and_lake_ic...</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[4.99625,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1d42f2d3-2456-485f-a93e-92f08bdd5c51</td>\n",
       "      <td>S1A_OPER_AUX_GNSSRD_POD__20220510T020122_V2022...</td>\n",
       "      <td>/eodata/Sentinel-1/AUX/AUX_GNSSRD/2022/05/03/S...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5c744d5c-c082-4a34-a181-81cde73cd25d</td>\n",
       "      <td>S1B_OPER_AUX_GNSSRD_POD__20220510T023113_V2022...</td>\n",
       "      <td>/eodata/Sentinel-1/AUX/AUX_GNSSRD/2022/05/03/S...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10,
   "source": [
    "json = requests.get(\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=not (Collection/Name eq 'SENTINEL-2') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-03T00:10:00.000Z&$orderby=ContentDate/Start&$top=100\").json()\n",
    "df = pd.DataFrame.from_dict(json['value'])\n",
    "\n",
    "# Print only specific columns\n",
    "columns_to_print = ['Id', 'Name','S3Path','GeoFootprint']\n",
    "df[columns_to_print].head(3)"
   ],
   "id": "1587080cb93ac0ef"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-15T17:39:39.437899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import getpass\n",
    "import requests\n",
    "import os\n",
    "import ast\n",
    "from time import sleep\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sentinelhub import (\n",
    "    SHConfig, DataCollection, SentinelHubCatalog,\n",
    "    BBox, bbox_to_dimensions, CRS\n",
    ")\n",
    "\n",
    "# --- Config ---\n",
    "config = SHConfig()\n",
    "time_interval = ('2024-06-01', '2025-06-30')\n",
    "aoi_coords_wgs84 = [-117.272555, 32.392761, -117.083041, 32.678348]\n",
    "resolution = 10\n",
    "utc_offset_hours = -7\n",
    "\n",
    "# --- AOI Setup ---\n",
    "aoi_bbox = BBox(bbox=aoi_coords_wgs84, crs=CRS.WGS84)\n",
    "aoi_size = bbox_to_dimensions(aoi_bbox, resolution=resolution)\n",
    "print(f\"Image shape at {resolution} m resolution: {aoi_size} pixels\")\n",
    "\n",
    "# --- Catalog Search ---\n",
    "catalog = SentinelHubCatalog(config=config)\n",
    "\n",
    "s1_results = list(catalog.search(\n",
    "    DataCollection.SENTINEL1_IW,\n",
    "    bbox=aoi_bbox,\n",
    "    time=time_interval,\n",
    "    fields={\"include\": [\"id\", \"properties.datetime\"], \"exclude\": []}\n",
    "))\n",
    "print(\"Sentinel-1 results:\", len(s1_results))\n",
    "\n",
    "s2_results = list(catalog.search(\n",
    "    DataCollection.SENTINEL2_L1C,\n",
    "    bbox=aoi_bbox,\n",
    "    time=time_interval,\n",
    "    fields={\"include\": [\"id\", \"properties.datetime\"], \"exclude\": []}\n",
    "))\n",
    "print(\"Sentinel-2 L1C results:\", len(s2_results))\n",
    "\n",
    "# --- Authentication ---\n",
    "auth_url = \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\"\n",
    "username = input(\"CDSE username: \")\n",
    "password = getpass.getpass(\"CDSE password: \")\n",
    "auth_data = {\n",
    "    'grant_type': 'password',\n",
    "    'client_id': 'cdse-public',\n",
    "    'username': username,\n",
    "    'password': password\n",
    "}\n",
    "\n",
    "def refresh_token():\n",
    "    global access_token, headers, token_acquired\n",
    "    auth_response = requests.post(auth_url, data=auth_data)\n",
    "    auth_response.raise_for_status()\n",
    "    access_token = auth_response.json()[\"access_token\"]\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    token_acquired = datetime.now()\n",
    "    print(\"🔁 Refreshed access token.\")\n",
    "\n",
    "refresh_token()\n",
    "token_valid_for_minutes = 55\n",
    "\n",
    "# --- Helper functions ---\n",
    "def get_product_name_by_id(sh_id):\n",
    "    if (datetime.now() - token_acquired) > timedelta(minutes=token_valid_for_minutes):\n",
    "        refresh_token()\n",
    "    url = f\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Name eq '{sh_id}'&$format=json\"\n",
    "    r = requests.get(url, headers=headers)\n",
    "    if r.status_code == 403:\n",
    "        print(f\"🚫 Forbidden for SH ID: {sh_id}\")\n",
    "        return None\n",
    "    r.raise_for_status()\n",
    "    items = r.json().get(\"value\", [])\n",
    "    return items[0][\"Name\"] if items else None\n",
    "\n",
    "# --- Filter non-COG products for Sentinel-2, allow COG for Sentinel-1 ---\n",
    "filtered_s1, filtered_s2 = [], []\n",
    "\n",
    "for item in s1_results:\n",
    "    name = get_product_name_by_id(item[\"id\"])\n",
    "    if name and name.endswith(\"_COG.SAFE\"):\n",
    "        filtered_s1.append({\n",
    "            \"id\": name,\n",
    "            \"datetime\": pd.to_datetime(item[\"properties\"][\"datetime\"]),\n",
    "            \"date\": pd.to_datetime(item[\"properties\"][\"datetime\"]).date()\n",
    "        })\n",
    "\n",
    "for item in s2_results:\n",
    "    name = get_product_name_by_id(item[\"id\"])\n",
    "    if name and not name.endswith(\"_COG.SAFE\"):\n",
    "        filtered_s2.append({\n",
    "            \"id\": name,\n",
    "            \"datetime\": pd.to_datetime(item[\"properties\"][\"datetime\"]),\n",
    "            \"date\": pd.to_datetime(item[\"properties\"][\"datetime\"]).date()\n",
    "        })\n",
    "\n",
    "# --- Create DataFrames ---\n",
    "df_s1 = pd.DataFrame(filtered_s1)\n",
    "df_s2 = pd.DataFrame(filtered_s2)\n",
    "\n",
    "common_dates = set(df_s1[\"date\"]).intersection(df_s2[\"date\"])\n",
    "print(\"Number of matching dates:\", len(common_dates))\n",
    "\n",
    "df_s1_common = df_s1[df_s1[\"date\"].isin(common_dates)]\n",
    "df_s2_common = df_s2[df_s2[\"date\"].isin(common_dates)]\n",
    "\n",
    "grouped_s1 = df_s1_common.groupby(\"date\")[\"id\"].apply(list).rename(\"s1_ids\")\n",
    "grouped_s2 = df_s2_common.groupby(\"date\")[\"id\"].apply(list).rename(\"s2_ids\")\n",
    "\n",
    "matched_df = pd.concat([grouped_s1, grouped_s2], axis=1).reset_index()\n",
    "\n",
    "matched_df.to_csv(\"matched_s1_s2_L2A.csv\", index=False)\n",
    "print(\"✅ Matched product list saved to matched_s1_s2_L2A.csv\")\n",
    "\n",
    "# --- Download functions ---\n",
    "def get_product_id(product_name):\n",
    "    def make_request():\n",
    "        return requests.get(\n",
    "            f\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Name eq '{product_name}'&$format=json\",\n",
    "            headers=headers\n",
    "        )\n",
    "\n",
    "    if (datetime.now() - token_acquired) > timedelta(minutes=token_valid_for_minutes):\n",
    "        refresh_token()\n",
    "\n",
    "    r = make_request()\n",
    "    if r.status_code == 403:\n",
    "        print(f\"⚠️ 403 for {product_name}, refreshing token and retrying...\")\n",
    "        refresh_token()\n",
    "        r = make_request()\n",
    "        if r.status_code == 403:\n",
    "            print(f\"🚫 Still forbidden after refresh: {product_name}\")\n",
    "            return None\n",
    "\n",
    "    r.raise_for_status()\n",
    "    items = r.json().get(\"value\", [])\n",
    "    return items[0][\"Id\"] if items else None\n",
    "\n",
    "def download_product(product_name, folder):\n",
    "    product_id = get_product_id(product_name)\n",
    "    if not product_id:\n",
    "        return\n",
    "    if (datetime.now() - token_acquired) > timedelta(minutes=token_valid_for_minutes):\n",
    "        refresh_token()\n",
    "    url = f\"https://download.dataspace.copernicus.eu/odata/v1/Products({product_id})/$value\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    out_path = os.path.join(folder, f\"{product_name}.zip\")\n",
    "    if os.path.exists(out_path):\n",
    "        print(f\"⏩ Already downloaded: {product_name}\")\n",
    "        return\n",
    "    print(f\"⬇️ Downloading: {product_name}\")\n",
    "    with requests.get(url, headers=headers, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(out_path, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "    print(f\"✅ Saved: {out_path}\")\n",
    "\n",
    "# --- Download loop ---\n",
    "for _, row in matched_df.iterrows():\n",
    "    print(f\"\\n📅 Processing date: {row['date']}\")\n",
    "    for s1_id in row[\"s1_ids\"]:\n",
    "        download_product(s1_id, folder=\"sentinel1\")\n",
    "        sleep(1)\n",
    "    for s2_id in row[\"s2_ids\"]:\n",
    "        download_product(s2_id, folder=\"sentinel2\")\n",
    "        sleep(1)\n"
   ],
   "id": "990c268d8f6d3be0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape at 10 m resolution: (1785, 3163) pixels\n",
      "Sentinel-1 results: 127\n",
      "Sentinel-2 L1C results: 315\n",
      "🔁 Refreshed access token.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:29:12.129220Z",
     "start_time": "2025-06-30T06:01:34.905497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import getpass\n",
    "import requests\n",
    "import os\n",
    "import ast\n",
    "from time import sleep\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sentinelhub import (\n",
    "    SHConfig, DataCollection, SentinelHubCatalog,\n",
    "    BBox, bbox_to_dimensions, CRS\n",
    ")\n",
    "\n",
    "# --- Config ---\n",
    "config = SHConfig()\n",
    "time_interval = ('2024-06-01', '2024-12-31')\n",
    "aoi_coords_wgs84 = [-117.272555, 32.392761, -117.083041, 32.678348]\n",
    "resolution = 10\n",
    "utc_offset_hours = -7\n",
    "\n",
    "# --- AOI Setup ---\n",
    "aoi_bbox = BBox(bbox=aoi_coords_wgs84, crs=CRS.WGS84)\n",
    "aoi_size = bbox_to_dimensions(aoi_bbox, resolution=resolution)\n",
    "print(f\"Image shape at {resolution} m resolution: {aoi_size} pixels\")\n",
    "\n",
    "# --- Catalog Search ---\n",
    "catalog = SentinelHubCatalog(config=config)\n",
    "\n",
    "s1_results = list(catalog.search(\n",
    "    DataCollection.SENTINEL1_IW,\n",
    "    bbox=aoi_bbox,\n",
    "    time=time_interval,\n",
    "    fields={\"include\": [\"id\", \"properties.datetime\"], \"exclude\": []}\n",
    "))\n",
    "print(\"Sentinel-1 results:\", len(s1_results))\n",
    "\n",
    "s2_results = list(catalog.search(\n",
    "    DataCollection.SENTINEL2_L2A,\n",
    "    bbox=aoi_bbox,\n",
    "    time=time_interval,\n",
    "    fields={\"include\": [\"id\", \"properties.datetime\"], \"exclude\": []}\n",
    "))\n",
    "print(\"Sentinel-2 L2A results:\", len(s2_results))\n",
    "\n",
    "# --- Authentication ---\n",
    "auth_url = \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\"\n",
    "username = input(\"CDSE username: \")\n",
    "password = getpass.getpass(\"CDSE password: \")\n",
    "auth_data = {\n",
    "    'grant_type': 'password',\n",
    "    'client_id': 'cdse-public',\n",
    "    'username': username,\n",
    "    'password': password\n",
    "}\n",
    "\n",
    "def refresh_token():\n",
    "    global access_token, headers, token_acquired\n",
    "    auth_response = requests.post(auth_url, data=auth_data)\n",
    "    auth_response.raise_for_status()\n",
    "    access_token = auth_response.json()[\"access_token\"]\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    token_acquired = datetime.now()\n",
    "    print(\"🔁 Refreshed access token.\")\n",
    "\n",
    "refresh_token()\n",
    "token_valid_for_minutes = 55\n",
    "\n",
    "# --- Filter non-COG products for Sentinel-2, allow COG for Sentinel-1 ---\n",
    "filtered_s1, filtered_s2 = [], []\n",
    "\n",
    "for item in s1_results:\n",
    "    name = item[\"id\"]\n",
    "    if name and name.endswith(\"_COG.SAFE\"):\n",
    "        filtered_s1.append({\n",
    "            \"id\": name,\n",
    "            \"datetime\": pd.to_datetime(item[\"properties\"][\"datetime\"]),\n",
    "            \"date\": pd.to_datetime(item[\"properties\"][\"datetime\"]).date()\n",
    "        })\n",
    "\n",
    "for item in s2_results:\n",
    "    name = item[\"id\"]\n",
    "    if name and not name.endswith(\"_COG.SAFE\"):\n",
    "        filtered_s2.append({\n",
    "            \"id\": name,\n",
    "            \"datetime\": pd.to_datetime(item[\"properties\"][\"datetime\"]),\n",
    "            \"date\": pd.to_datetime(item[\"properties\"][\"datetime\"]).date()\n",
    "        })\n",
    "\n",
    "# --- Create DataFrames ---\n",
    "df_s1 = pd.DataFrame(filtered_s1)\n",
    "df_s2 = pd.DataFrame(filtered_s2)\n",
    "\n",
    "common_dates = set(df_s1[\"date\"]).intersection(df_s2[\"date\"])\n",
    "print(\"Number of matching dates:\", len(common_dates))\n",
    "\n",
    "df_s1_common = df_s1[df_s1[\"date\"].isin(common_dates)]\n",
    "df_s2_common = df_s2[df_s2[\"date\"].isin(common_dates)]\n",
    "\n",
    "grouped_s1 = df_s1_common.groupby(\"date\")[\"id\"].apply(list).rename(\"s1_ids\")\n",
    "grouped_s2 = df_s2_common.groupby(\"date\")[\"id\"].apply(list).rename(\"s2_ids\")\n",
    "\n",
    "matched_df = pd.concat([grouped_s1, grouped_s2], axis=1).reset_index()\n",
    "\n",
    "matched_df.to_csv(\"matched_s1_s2_L2A.csv\", index=False)\n",
    "print(\"✅ Matched product list saved to matched_s1_s2_L2A.csv\")\n",
    "\n",
    "# --- Download functions ---\n",
    "def get_product_id(product_name):\n",
    "    def make_request():\n",
    "        return requests.get(\n",
    "            f\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Name eq '{product_name}'&$format=json\",\n",
    "            headers=headers\n",
    "        )\n",
    "\n",
    "    if (datetime.now() - token_acquired) > timedelta(minutes=token_valid_for_minutes):\n",
    "        refresh_token()\n",
    "\n",
    "    r = make_request()\n",
    "    if r.status_code == 403:\n",
    "        print(f\"⚠️ 403 for {product_name}, refreshing token and retrying...\")\n",
    "        refresh_token()\n",
    "        r = make_request()\n",
    "        if r.status_code == 403:\n",
    "            print(f\"🚫 Still forbidden after refresh: {product_name}\")\n",
    "            return None\n",
    "\n",
    "    r.raise_for_status()\n",
    "    items = r.json().get(\"value\", [])\n",
    "    return items[0][\"Id\"] if items else None\n",
    "\n",
    "def download_product(product_name, folder):\n",
    "    product_id = get_product_id(product_name)\n",
    "    if not product_id:\n",
    "        return\n",
    "    if (datetime.now() - token_acquired) > timedelta(minutes=token_valid_for_minutes):\n",
    "        refresh_token()\n",
    "    url = f\"https://download.dataspace.copernicus.eu/odata/v1/Products({product_id})/$value\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    out_path = os.path.join(folder, f\"{product_name}.zip\")\n",
    "    if os.path.exists(out_path):\n",
    "        print(f\"⏩ Already downloaded: {product_name}\")\n",
    "        return\n",
    "    print(f\"⬇️ Downloading: {product_name}\")\n",
    "    with requests.get(url, headers=headers, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(out_path, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "    print(f\"✅ Saved: {out_path}\")\n",
    "\n",
    "# --- Download loop ---\n",
    "for _, row in matched_df.iterrows():\n",
    "    print(f\"\\n📅 Processing date: {row['date']}\")\n",
    "    for s1_id in row[\"s1_ids\"]:\n",
    "        download_product(s1_id, folder=\"sentinel1\")\n",
    "        sleep(1)\n",
    "    for s2_id in row[\"s2_ids\"]:\n",
    "        download_product(s2_id, folder=\"sentinel2\")\n",
    "        sleep(1)\n",
    "\n"
   ],
   "id": "90b9e55e7401c1a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape at 10 m resolution: (1785, 3163) pixels\n",
      "Sentinel-1 results: 57\n",
      "Sentinel-2 L2A results: 165\n",
      "🔁 Refreshed access token.\n",
      "Number of matching dates: 13\n",
      "✅ Matched product list saved to matched_s1_s2_L2A.csv\n",
      "\n",
      "📅 Processing date: 2024-06-26\n",
      "⏩ Already downloaded: S1A_IW_GRDH_1SDV_20240626T134456_20240626T134521_054495_06A1B9_E2D5_COG.SAFE\n",
      "⏩ Already downloaded: S2A_MSIL2A_20240626T182921_N0510_R027_T11SMR_20240627T003249.SAFE\n",
      "⏩ Already downloaded: S2A_MSIL2A_20240626T182921_N0510_R027_T11SMS_20240627T003249.SAFE\n",
      "\n",
      "📅 Processing date: 2024-07-01\n",
      "⏩ Already downloaded: S1A_IW_GRDH_1SDV_20240701T135318_20240701T135343_054568_06A44B_DBD2_COG.SAFE\n",
      "⏩ Already downloaded: S1A_IW_GRDH_1SDV_20240701T015016_20240701T015045_054561_06A407_2F9B_COG.SAFE\n",
      "⏩ Already downloaded: S2B_MSIL2A_20240701T182919_N0510_R027_T11SMR_20240701T223927.SAFE\n",
      "⏩ Already downloaded: S2B_MSIL2A_20240701T182919_N0510_R027_T11SMS_20240701T223927.SAFE\n",
      "\n",
      "📅 Processing date: 2024-07-13\n",
      "⏩ Already downloaded: S1A_IW_GRDH_1SDV_20240713T135318_20240713T135343_054743_06AA5A_70DD_COG.SAFE\n",
      "⏩ Already downloaded: S1A_IW_GRDH_1SDV_20240713T015016_20240713T015045_054736_06AA18_A9F6_COG.SAFE\n",
      "⏩ Already downloaded: S2A_MSIL2A_20240713T181921_N0510_R127_T11SMR_20240714T010258.SAFE\n",
      "⏩ Already downloaded: S2A_MSIL2A_20240713T181921_N0510_R127_T11SMS_20240714T010258.SAFE\n",
      "\n",
      "📅 Processing date: 2024-08-25\n",
      "⏩ Already downloaded: S1A_IW_GRDH_1SDV_20240825T134455_20240825T134520_055370_06C0B3_8436_COG.SAFE\n",
      "⏩ Already downloaded: S2A_MSIL2A_20240825T182921_N0511_R027_T11SMR_20240826T015359.SAFE\n",
      "⏩ Already downloaded: S2A_MSIL2A_20240825T182921_N0511_R027_T11SMS_20240826T015359.SAFE\n",
      "\n",
      "📅 Processing date: 2024-08-30\n",
      "⏩ Already downloaded: S1A_IW_GRDH_1SDV_20240830T135318_20240830T135343_055443_06C35B_AD5F_COG.SAFE\n",
      "⏩ Already downloaded: S1A_IW_GRDH_1SDV_20240830T015015_20240830T015045_055436_06C312_B442_COG.SAFE\n",
      "⏩ Already downloaded: S2B_MSIL2A_20240830T182919_N0511_R027_T11SMR_20240830T235532.SAFE\n",
      "⏩ Already downloaded: S2B_MSIL2A_20240830T182919_N0511_R027_T11SMS_20240830T235532.SAFE\n",
      "\n",
      "📅 Processing date: 2024-09-06\n",
      "⏩ Already downloaded: S1A_IW_GRDH_1SDV_20240906T134455_20240906T134520_055545_06C745_7FC0_COG.SAFE\n",
      "⏩ Already downloaded: S2B_MSIL2A_20240906T181919_N0511_R127_T11SMR_20240907T002550.SAFE\n",
      "⏩ Already downloaded: S2B_MSIL2A_20240906T181919_N0511_R127_T11SMS_20240907T002550.SAFE\n",
      "\n",
      "📅 Processing date: 2024-09-11\n",
      "⏩ Already downloaded: S1A_IW_GRDH_1SDV_20240911T135318_20240911T135343_055618_06CA33_0075_COG.SAFE\n",
      "⬇️ Downloading: S1A_IW_GRDH_1SDV_20240911T015016_20240911T015045_055611_06C9E7_FA51_COG.SAFE\n",
      "✅ Saved: sentinel1/S1A_IW_GRDH_1SDV_20240911T015016_20240911T015045_055611_06C9E7_FA51_COG.SAFE.zip\n",
      "⬇️ Downloading: S2A_MSIL2A_20240911T181931_N0511_R127_T11SMR_20240912T012150.SAFE\n",
      "✅ Saved: sentinel2/S2A_MSIL2A_20240911T181931_N0511_R127_T11SMR_20240912T012150.SAFE.zip\n",
      "⬇️ Downloading: S2A_MSIL2A_20240911T181931_N0511_R127_T11SMS_20240912T012150.SAFE\n",
      "✅ Saved: sentinel2/S2A_MSIL2A_20240911T181931_N0511_R127_T11SMS_20240912T012150.SAFE.zip\n",
      "\n",
      "📅 Processing date: 2024-10-24\n",
      "⬇️ Downloading: S1A_IW_GRDH_1SDV_20241024T134456_20241024T134521_056245_06E2F3_79ED_COG.SAFE\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[27]\u001B[39m\u001B[32m, line 155\u001B[39m\n\u001B[32m    153\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m📅 Processing date: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrow[\u001B[33m'\u001B[39m\u001B[33mdate\u001B[39m\u001B[33m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    154\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m s1_id \u001B[38;5;129;01min\u001B[39;00m row[\u001B[33m\"\u001B[39m\u001B[33ms1_ids\u001B[39m\u001B[33m\"\u001B[39m]:\n\u001B[32m--> \u001B[39m\u001B[32m155\u001B[39m     \u001B[43mdownload_product\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms1_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfolder\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43msentinel1\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    156\u001B[39m     sleep(\u001B[32m1\u001B[39m)\n\u001B[32m    157\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m s2_id \u001B[38;5;129;01min\u001B[39;00m row[\u001B[33m\"\u001B[39m\u001B[33ms2_ids\u001B[39m\u001B[33m\"\u001B[39m]:\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[27]\u001B[39m\u001B[32m, line 147\u001B[39m, in \u001B[36mdownload_product\u001B[39m\u001B[34m(product_name, folder)\u001B[39m\n\u001B[32m    145\u001B[39m     r.raise_for_status()\n\u001B[32m    146\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(out_path, \u001B[33m'\u001B[39m\u001B[33mwb\u001B[39m\u001B[33m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m--> \u001B[39m\u001B[32m147\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mr\u001B[49m\u001B[43m.\u001B[49m\u001B[43miter_content\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunk_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m8192\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    148\u001B[39m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    149\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m✅ Saved: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mout_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/RS/lib/python3.13/site-packages/requests/models.py:820\u001B[39m, in \u001B[36mResponse.iter_content.<locals>.generate\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    818\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m.raw, \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m    819\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m820\u001B[39m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m.raw.stream(chunk_size, decode_content=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    821\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m ProtocolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    822\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m ChunkedEncodingError(e)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/RS/lib/python3.13/site-packages/urllib3/response.py:1066\u001B[39m, in \u001B[36mHTTPResponse.stream\u001B[39m\u001B[34m(self, amt, decode_content)\u001B[39m\n\u001B[32m   1064\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1065\u001B[39m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_fp_closed(\u001B[38;5;28mself\u001B[39m._fp) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m._decoded_buffer) > \u001B[32m0\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m1066\u001B[39m         data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m=\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1068\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[32m   1069\u001B[39m             \u001B[38;5;28;01myield\u001B[39;00m data\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/RS/lib/python3.13/site-packages/urllib3/response.py:955\u001B[39m, in \u001B[36mHTTPResponse.read\u001B[39m\u001B[34m(self, amt, decode_content, cache_content)\u001B[39m\n\u001B[32m    952\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m._decoded_buffer) >= amt:\n\u001B[32m    953\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._decoded_buffer.get(amt)\n\u001B[32m--> \u001B[39m\u001B[32m955\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_raw_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    957\u001B[39m flush_decoder = amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m (amt != \u001B[32m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data)\n\u001B[32m    959\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m._decoded_buffer) == \u001B[32m0\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/RS/lib/python3.13/site-packages/urllib3/response.py:879\u001B[39m, in \u001B[36mHTTPResponse._raw_read\u001B[39m\u001B[34m(self, amt, read1)\u001B[39m\n\u001B[32m    876\u001B[39m fp_closed = \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m._fp, \u001B[33m\"\u001B[39m\u001B[33mclosed\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m    878\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._error_catcher():\n\u001B[32m--> \u001B[39m\u001B[32m879\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_fp_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mread1\u001B[49m\u001B[43m=\u001B[49m\u001B[43mread1\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fp_closed \u001B[38;5;28;01melse\u001B[39;00m \u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    880\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt != \u001B[32m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data:\n\u001B[32m    881\u001B[39m         \u001B[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001B[39;00m\n\u001B[32m    882\u001B[39m         \u001B[38;5;66;03m# Close the connection when no data is returned\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    887\u001B[39m         \u001B[38;5;66;03m# not properly close the connection in all cases. There is\u001B[39;00m\n\u001B[32m    888\u001B[39m         \u001B[38;5;66;03m# no harm in redundantly calling close.\u001B[39;00m\n\u001B[32m    889\u001B[39m         \u001B[38;5;28mself\u001B[39m._fp.close()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/RS/lib/python3.13/site-packages/urllib3/response.py:862\u001B[39m, in \u001B[36mHTTPResponse._fp_read\u001B[39m\u001B[34m(self, amt, read1)\u001B[39m\n\u001B[32m    859\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._fp.read1(amt) \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m._fp.read1()\n\u001B[32m    860\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    861\u001B[39m     \u001B[38;5;66;03m# StringIO doesn't like amt=None\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m862\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_fp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m._fp.read()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:479\u001B[39m, in \u001B[36mHTTPResponse.read\u001B[39m\u001B[34m(self, amt)\u001B[39m\n\u001B[32m    476\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.length \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt > \u001B[38;5;28mself\u001B[39m.length:\n\u001B[32m    477\u001B[39m     \u001B[38;5;66;03m# clip the read to the \"end of response\"\u001B[39;00m\n\u001B[32m    478\u001B[39m     amt = \u001B[38;5;28mself\u001B[39m.length\n\u001B[32m--> \u001B[39m\u001B[32m479\u001B[39m s = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    480\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m s \u001B[38;5;129;01mand\u001B[39;00m amt:\n\u001B[32m    481\u001B[39m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[32m    482\u001B[39m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[32m    483\u001B[39m     \u001B[38;5;28mself\u001B[39m._close_conn()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001B[39m, in \u001B[36mSocketIO.readinto\u001B[39m\u001B[34m(self, b)\u001B[39m\n\u001B[32m    717\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mcannot read from timed out object\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    718\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m719\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sock\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    720\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[32m    721\u001B[39m     \u001B[38;5;28mself\u001B[39m._timeout_occurred = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1304\u001B[39m, in \u001B[36mSSLSocket.recv_into\u001B[39m\u001B[34m(self, buffer, nbytes, flags)\u001B[39m\n\u001B[32m   1300\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m flags != \u001B[32m0\u001B[39m:\n\u001B[32m   1301\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1302\u001B[39m           \u001B[33m\"\u001B[39m\u001B[33mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m\"\u001B[39m %\n\u001B[32m   1303\u001B[39m           \u001B[38;5;28mself\u001B[39m.\u001B[34m__class__\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1304\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1305\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1306\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1138\u001B[39m, in \u001B[36mSSLSocket.read\u001B[39m\u001B[34m(self, len, buffer)\u001B[39m\n\u001B[32m   1136\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1137\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1138\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sslobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1139\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1140\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sslobj.read(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
